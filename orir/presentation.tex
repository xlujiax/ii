\documentclass{beamer}
\usetheme{Antibes}
\usecolortheme{seagull}
\setbeamertemplate{footline}{\hfill\insertframenumber/\inserttotalframenumber\hspace*{.5cm}}
\setbeamertemplate{navigation symbols}{}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage{hyperref}
\usepackage{rotating}
\usepackage{listings}

\title{Obliczenia równoległe i rozproszone}
\author{Maciej Pacut}
\date{Luty 2012}

\AtBeginSubsection[]
{
  \begin{frame}<beamer>
    \frametitle{Layout}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\section{Wstęp}
\begin{frame}{Temat prezentacji}
  A. Karbowski, Programowanie równoległe i rozproszone - rozdziały 1,2,3
  \begin{enumerate}
  \item Motywacje do obliczeń równoległych
  \item Podstawowe pojęcia
  \item Skalowalność
  \item Typy równoległości
  \item Klastry i gridy
  \end{enumerate}
\end{frame}
\section{Rozdział 1}

\begin{frame}{Przykłady przetwarzania równoległego}
  \begin{enumerate}
  \item Wiele kas na poczcie
  \item Kolejne stanowiska na taśmie produkcyjnej
  \item Hierarchia w firmie - zarządzanie zespołami
  \item Musztra, układy taneczne
  \end{enumerate}
\end{frame}

\begin{frame}{Przykłady przetwarzania równoległego (odpowiedniki w informatyce)}
  \begin{enumerate}
  \item Wiele kas na poczcie (przetwarzanie niezależnych zadań)
  \item Kolejne stanowiska na taśmie produkcyjnej (pipelining)
  \item Hierarchia w firmie - zarządzanie zespołami (koordynator - jednostki lokalne)
  \item Musztra, układy taneczne (array parallelism)
  \end{enumerate}
\end{frame}

\begin{frame}{Zalety obliczeń równoległych}
  \begin{enumerate}
  \item Przyspieszenie czasu przeprowadzania obliczeń
  \item Zwiększenie precyzji wykonywanych obliczen
  \item Zwiększenie niezawodności obliczeń
  \item Stworzenie możliwości rozwiązania zadań zbyt dużych dla jednej maszyny sekwencyjnej
  \item Umożliwienie wykorzystania pełnej mocy obliczeniowej procesorów wielordzeniowych
  \end{enumerate}
\end{frame}

\begin{frame}{Podstawowe pojęcia}
  \begin{enumerate}
  \item Obliczenia współbieżne - następne zadanie rozpoczyna się zanim skończy się poprzednie (mogą być przeprowadzane na jednym procesorze z podziałem czasu)
  \item Obliczenia równoległe - obliczenia współbieżne na wielu procesorach
  \item Obliczenia rozproszone - obliczenia bez dzielonej pamięci (przekazywanie komunikatów)
  \end{enumerate}
\end{frame}

\begin{frame}{Przykłady problemów, których rozwiązanie jest możliwe tylko za pomocą algorytmów rozproszonych}
  \begin{enumerate}
  \item Prognoza pogody - dwa dni po
  \item Dane z teleskopów
  \end{enumerate}
\end{frame}

\section{Rozdział 2}

\begin{frame}{Prawo Amdahla}
  \begin{enumerate}
  \item Mówi o ograniczeniu górnym przyspieszenia wykonywania zadania przy przenoszeniu z procesora sekwencyjnego na wieloprocesory
  \item Wzorek, opis zmiennych i funkcji
  \end{enumerate}
\end{frame}
\section{Rozdział 3}


\begin{frame}{Procesory wielordzeniowe}
  \begin{enumerate}
  \item wiele jednostek obliczeniowych dzielących magistralę
  \item czasami też L2 cache
  \end{enumerate}
\end{frame}

\begin{frame}{Hyper Threading}
  \begin{enumerate}
  \item wolne cykle (czekanie na IO)
  \item dwa wątki na procesorze jednordzeniowym z powodu dużej liczby wolnych cykli
  \item wątki są przełączane
  \end{enumerate}
\end{frame}

\begin{frame}{Rozszerzenia strumieniowe}
  \begin{enumerate}
  \item realizacja podstawowych operacji arytmetycznych na wektorze w sposób równoległy
  \item dodatkowe jendostki przeznaczone tylko do tej pracy
  \end{enumerate}
\end{frame}

\begin{frame}{Obliczenia na kartach graficznych}
  \begin{enumerate}
  \item kary graficzne maja wiele jednostek przetwarzajacych dane (nawet kilkaset)
  \item jest to konsekwencją [w dużej mierze] równoległej natury procesu wyświetlania grafiki
  \item kiedyś potok graficzny był nieprogramowalny - algorytmy do przetwarzania wierzchołków/pikseli były zapisane w sprzęcie
  \end{enumerate}
\end{frame}

\begin{frame}{Obliczenia na kartach graficznych 2}
  \begin{enumerate}
  \item jednostki przetwarzania ogólnego zastosowania
  \item pojawienie się shaderów
  \item koniec stałego potoku graficznego
  \item GPGPU - General Purpose Computing on Graphics Procesing Units
  \item Tesla - nVidia, FireStream - AMD
  \end{enumerate}
\end{frame}

\begin{frame}{Hybrydyzacja obliczeń}
  \begin{enumerate}
  \item czyli korzystanie z różnorodnych jednostek wykonawczych
  \item różne reprezentacje typów danych (endianness: PowerPC - big, x86 - little)
  \item różne precyzje typów danych (halves/partials na GPU to liczby zmiennoprzecinkowe 16-bitowe, są też 32-bitowe)
  \item IBM Roadrunner - kilkanaście tysięcy procesorów AMD (2 rdzenie, x86) i tyle samo procesorów z Playstation 3 (1 rdzeń PowerPC, 8 rdzeni do obliczeń wektorowych)
  \end{enumerate}
\end{frame}

\begin{frame}{Krótko o superkomputerach}
  \begin{enumerate}
  \item Najczęściej są to połączone procesory spotykane w komputerach osobistych
  \item Klastry wieloprocesorów (wspólna pamięć) połączone szybkimi sieciami wewnętrznymi
  \item Coraz rzadziej wykorzystuje się procesory dedykowane do obliczeń wektorowych
  \end{enumerate}
\end{frame}

\section{Klasyfikacja maszyn równoległych}

\begin{frame}{Klasyfikacja maszyn równoległych wg Flynna}
  \begin{enumerate}
  \item SISD - klasyczna maszyna sekwencyjna
  \item SIMD - procesory wektorowe, procesory z jednostkami wktorowymi
  \item MISD - tylko specyficzne zastosowania
  \item MIMD - równoległa praca na wielu różnych danych
  \end{enumerate}
\end{frame}

\begin{frame}{Klasyfikacja maszyn równoległych ze względu na rodzaj pamięci}
  \begin{enumerate}
  \item Pamięć dzielona - wspólna przestrzeń adresowa
  \item Pamięć lokalna - należy samemu podzielić dane
  \end{enumerate}
\end{frame}

\begin{frame}{Równoległość w maszynach typu SISD}
  \begin{enumerate}
  \item Przetwarzanie potokowe - kilka taktów na instrukcję (pobranie rozkazu, jego argumentów, operacje arytmetyczne, zapis, ...); w momencie zwolnienia fragmentu procesora rozpoczynane jest wykonywanie następnej instrukcji
  \item Rozszerzenia strumieniowe - nowe rozkazy procesora wykonujące obliczenia równoległe na danych mniejszej precyzji (przykłady: MMX, SSE$\{\epsilon,2,3\}$, AltiVec, 3DNow!)
  \item Hyper Threading - dwa wątki na procesor przełączane przy oczekiwaniu na IO
  \end{enumerate}
\end{frame}

\begin{frame}{Równoległość w maszynach typu SIMD}
  \begin{enumerate}
  \item SM-SIMD
  \item DM-SIMD
  \end{enumerate}
\end{frame}

\begin{frame}{Równoległość w maszynach typu SM-SIMD}
  \begin{enumerate}
  \item Inaczej komputer wektorowy - składa się z jednego procesora wektorowego
  \item Dane zawsze są w paczkach o stałej liczności zależnej od procesora wektorowego
  \item Wykonywanie ciągów tych samych operacji
  \item Zaleta: łatwe programowanie takich maszyn
  \end{enumerate}
\end{frame}

\begin{frame}{Równoległość w maszynach typu DM-SIMD}
  \begin{enumerate}
  \item Siatka 2D lub 3D prostych procesorów + procesor nadzorujący
  \item Każdy prosty procesor ma swoje dane lokalne i na nich wykonuje obliczenia zlecone przez procesor nadzorujący
  \item Szybka wymiana informacji między sąsiednimi prostymi procesorami
  \item Powolny routing między dalszymi procesorami
  \item Ten model realizują karty graficzne
  \item Programista odpowiada za podział pamięci
  \end{enumerate}
\end{frame}

\begin{frame}{Równoległość w maszynach typu MIMD}
  \begin{enumerate}
  \item SM-MIMD
  \item DM-MIMD
  \end{enumerate}
\end{frame}

\begin{frame}{Równoległość w maszynach typu SM-MIMD}
  \begin{enumerate}
  \item Niewielka liczba procesorów z lokalną pamięcią
  \item Dostęp do globalnej pamięci
  \item Magistrala (tania - liniowo połączeń do niej, wolniejsza) lub przełączniki krzyżowe (drogie - $p^2$ przełączników, szybsze)
  \item Cache'ing z powodu drogiego dostępu do globalnej pamięci; utrzymywanie spójności
  \item Łatwość programowania z powodu istnienia wspólnej przestrzeni adresowej
  \end{enumerate}
\end{frame}

\begin{frame}{Równoległość w maszynach typu DM-MIMD}
  \begin{enumerate}
  \item Najpopularniejsza i najdynamiczniej rozwijana
  \item Lokalna pamięć każdego procesora
  \item Trudniejsze programowanie ze względu na konieczność przesyłania komunikatów
  \end{enumerate}
\end{frame}

\begin{frame}{Topologia maszyn typu DM-MIMD}
  \begin{enumerate}
  \item Topologia to sposów połączeń procesorów
  \item Średnica (mniejsza wartość lepsza)
  \item Podział połówkowy - najmniejsza liczba kanałów, po usunięciu których system będzie podzielony na dwie równe części (większa wartość lepsza)
  \end{enumerate}
\end{frame}

\begin{frame}{Przykładowe topologie maszyn typu DM-MIMD}
  \begin{enumerate}
  \item siatka dwuwymiarowa
  \item torus dwuwymiarowy
  \item pierścień (również torus jednowymiarowy)
  \item drzewa statyczne (wierzchołki = procesory)
  \item drzewa statyczne (liście = procesy, pozostałe to przełączniki)
  \item fat tree (o zwiększaniu przepustowości przy korzeniu)
  \item hipersześcian (można otrzymać inne topologie przez usuwanie krawędzi np. software'owo)
  \end{enumerate}
\end{frame}

\begin{frame}{Przykładowe topologie maszyn typu DM-MIMD}
  \begin{enumerate}
  \item cut-throught switching (siatka, podział pakietów)
  \item konstelacje - rozwiązanie hybyrdowe: węzły SM-MIMD połączone wolniejszą siecią (wolniejszą niż procesory wewnątrz węzła)
  \end{enumerate}
\end{frame}

\section{Klastry i gridy}

\begin{frame}{Klastry}
  \begin{enumerate}
  \item df.: zespół maszyn połączonych szybką siecią, które są jednolicie zarządzane
  \item najczęściej oparte na tej samej architekturze (homogeniczne)
  \item najczęściej pracujące pod kontrolą jednego systemu operacyjnego
  \item najczęściej znajdujące się blisko (np. regał lub pomieszcznie)
  \item najczęściej zarządzane z jednej stacji roboczej
  \end{enumerate}
\end{frame}

\begin{frame}{Klastry realizują wiele zadań jednocześnie}
  \begin{enumerate}
  \item job scheduler (priorytet zadania, kierowanie do mniej obciążonych maszyn)
  \item konieczność mierzenia obciążenia (tzw. load balancing clusters)
  \item dążenie do wrażenia, że klaster to jedna maszyna (system plików, scheduler); tzw. Single System Image
  \end{enumerate}
\end{frame}

\begin{frame}{Przykłady oprogramowania dla klastrów}
  \begin{enumerate}
  \item Portable Batch System - najstarszy
  \item Condor - możliwość przenosznia zadań w trakcie realizacji
  \item Oracle Grid Engine - opensource (wcześniej Sun Grid Engine)
  \item Windows Compute Cluster Server - tylko x86
  \item OpenSSI - firmy HP, darmowy
  \item Kerrighed - powstał w INRIA, migracje zadań
  \item Linux Virtual Server - modyfikacje jądra w celu uzyskania SSI, migracje zadań
  \end{enumerate}
\end{frame}

\begin{frame}{Gridy}
  \begin{enumerate}
  \item df.: zbiór luźno powiązanych, rozproszonych geograficznie, heterogenicznych zasobów komunikujących się z użyciem ustalonego protokołu
  \item zasoby to: superkomputery, klastry, pc z GPU, bazy danych, aparatura naukowa, urządzenia wyjścia
  \item uogólnienie klastra
  \item większe opóźnienia - nie nadają się do obliczeń równoległych tylko rozproszonych
  \item problem podszywania się pod element grida
  \end{enumerate}
\end{frame}

\begin{frame}{Zastosowania gridów i klastrów}
  \begin{enumerate}
  \item klastry nadają się do obliczeń numerycznych, optymalizacji
  \item gridy nadają się do ...
  \item seti at home, fightAISD at home
  \end{enumerate}
\end{frame}

\end{document}
