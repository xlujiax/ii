\documentclass{beamer}
\usetheme{Antibes}
\usecolortheme{seagull}
\setbeamertemplate{footline}{\hfill\insertframenumber/\inserttotalframenumber\hspace*{.5cm}}
\setbeamertemplate{navigation symbols}{}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage{hyperref}
\usepackage{rotating}
\usepackage{listings}

\title{Obliczenia równoległe i rozproszone}
\author{Maciej Pacut}
\date{Luty 2012}

\AtBeginSubsection[]
{
  \begin{frame}<beamer>
    \frametitle{Layout}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}

\begin{document}

\section{O prezentacji}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Temat prezentacji}
  A. Karbowski, Programowanie równoległe i rozproszone
  \begin{enumerate}
  \item Rodział 1 - Wprowadzenia
  \item Rodział 2 - Miary efektywności zrównoleglenia
  \item Rodział 3 - Architektury maszyn równoległych
  \end{enumerate}
\end{frame}

\begin{frame}{Zagadnienia poruszane w prezentacji}
  \begin{enumerate}
  \item Motywacje do obliczeń równoległych
  \item Podstawowe pojęcia
  \item Efektywność zrównoleglenia
  \item Typy równoległości
  \item Klastry i gridy
  \end{enumerate}
\end{frame}

\section{Rodział 1. Wprowadzenie}

\begin{frame}{Wprowadzenie}
  \huge
  \begin{center}
    Rodział 1

    Wprowadzenie

    \large
    [do programowania równoległego i rozproszonego]
  \end{center}
\end{frame}


\begin{frame}{Przykłady przetwarzania równoległego}
  \begin{enumerate}
  \item Wiele kas na poczcie
  \item Kolejne stanowiska na taśmie produkcyjnej
  \item Hierarchia w firmie - zarządzanie zespołami
  \item Musztra, układy taneczne
  \end{enumerate}
\end{frame}

\begin{frame}{Przykłady przetwarzania równoległego (odpowiedniki w informatyce)}
  \begin{enumerate}
  \item Wiele kas na poczcie (przetwarzanie niezależnych zadań)
  \item Kolejne stanowiska na taśmie produkcyjnej (pipelining)
  \item Hierarchia w firmie - zarządzanie zespołami (koordynator - jednostki lokalne)
  \item Musztra, układy taneczne (array parallelism)
  \end{enumerate}
\end{frame}

\begin{frame}{Zalety obliczeń równoległych}
  \begin{enumerate}
  \item Przyspieszenie czasu przeprowadzania obliczeń
  \item Zwiększenie precyzji wykonywanych obliczen
  \item Zwiększenie niezawodności obliczeń
  \item Stworzenie możliwości rozwiązania zadań zbyt dużych dla jednej maszyny sekwencyjnej
  \item Umożliwienie wykorzystania pełnej mocy obliczeniowej procesorów wielordzeniowych
  \end{enumerate}
\end{frame}

\begin{frame}{Podstawowe pojęcia}
  \begin{enumerate}
  \item Obliczenia współbieżne - następne zadanie rozpoczyna się zanim skończy się poprzednie (mogą być przeprowadzane na jednym procesorze z podziałem czasu)
  \item Obliczenia równoległe - obliczenia współbieżne na wielu procesorach
  \item Obliczenia rozproszone - obliczenia bez dzielonej pamięci (przekazywanie komunikatów)
  \end{enumerate}
\end{frame}

\begin{frame}{Przykłady problemów, których rozwiązanie jest możliwe tylko za pomocą algorytmów rozproszonych}
  \begin{enumerate}
  \item Systemy czasu rzeczywistego - prognoza pogody, wyszukiwarki internetowe
  \item Dane potrzebe stosunkowo szybko, ale nie w RT - modelowanie efektu cieplarnianego, badania nad lekami, diagnozy
  \item Zbyt duże dane - dane z teleskopów, badania w genetyce, modele aerodynamiczne, badania w fizyce
  \end{enumerate}
\end{frame}

\section{Rozdział 2. Miary efektywności zrównoleglenia}

\begin{frame}{Miary efektywności zrównoleglenia}
  \huge
  \begin{center}
    Rodział 2

    Miary efektywności zrównoleglenia
  \end{center}
\end{frame}

\begin{frame}{Miary efektywności zrównoleglenia}
  \begin{enumerate}
  \item Górne ograniczenie przyspieszenia przy przenoszeniu z procesora sekwencyjnego na wieloprocesory
  \item Sprawność oraz skalowalność
  \end{enumerate}
\end{frame}

\begin{frame}{Oznaczenia}
  \begin{enumerate}
  \item $n$ - wielkość zadania
  \item $p$ - liczba procesorów
  \item $T(n,p)$ - optymalny czas wykonania algorytmu na $p$ procesorach
  \item $T\beta(n,p)$ - wielkość sekwencyjnej części algorytmu; nie musi być spójna
  \end{enumerate}
\end{frame}

\begin{frame}{Współczynnik przyspieszenia}
  $$ S(n,p) = \frac{T(n,1)}{T(n,p)} $$
  $$ S(n,p) \leq p$$
\end{frame}

\begin{frame}{Czas wykonania części sekwencyjnej jest niezależny od p}
  $$ \beta(n,p) T(n, p) = const \hspace{1cm}\mbox{p = 1,2,..} $$
\end{frame}

\begin{frame}{Szacowanie czasu wykonania zadania na wielorpocesorze}
  $$ T(n,p) = \beta(n,p) T(n,p) + \frac{(1-\beta(n,1) T(n,1))}{p} $$
\end{frame}


\begin{frame}{Prawo Amdahla}
  $$ S(n,p) = \frac{T(n,1)}{T(n,p)} = \frac{1}{\beta(n,1) + \frac{1 - \beta(n,1)}{p}} $$
\end{frame}

\begin{frame}{Konsekwencja prawa Amdahla}
  $$ \lim_{p \rightarrow \infty}S(n,p) \rightarrow \frac{1}{\beta(n,1)} $$

  Nie da się programu przyspieszyć bardziej niż odwrotność udziału części sekwencyjnej w programie wykonywanym na jednym procesorze.
\end{frame}

\begin{frame}{Konsekwencja prawa Amdahla}
  Już gdy część sekwencyjna jest $n$ razy tańsza od części równoległej mamy:

  $$ \lim_{n \rightarrow 0} \beta(n,1) \rightarrow 0 $$
  $$ \lim_{n \rightarrow 0} S(n,p) \rightarrow p $$

  Czyli powodem stosowania obliczeń równoległych jest chęć rozwiązania problemów od dużym rozmiarze a nie chęć szybkiego otrzymania wyniku dla małego problemu.
\end{frame}

\begin{frame}{Skalowalność}
  Skalowalność to elastyczne dostosowywanie się do wzrostu liczby procesorów.

  $$ w(n) \mbox{ - liczba operacji}$$
  $$ h(n, p) \mbox{ - narzut na komunikację}$$
  $$ \eta(n,p) \mbox{ - skalowalność} $$


  $$ \eta(n,p) = \frac{w(n)}{w(n) + h(n,p)} = \frac{1}{1 + \frac{h(n,p)}{w(n)}} $$
\end{frame}

\begin{frame}{Obserwacje dotyczące skalowalności}
  $$ \eta(n,p) = \frac{w(n)}{w(n) + h(n,p)} = \frac{1}{1 + \frac{h(n,p)}{w(n)}} $$

  \begin{enumerate}
  \item Narzuty na komunikację rosną wraz z liczbą procesorów
  \item Sprawność maleje, gdy nie zmieniając rozmiaru zadania, zwiększymy liczbę procesorów
  \item Chcąc utrzymać sprawność po zwiększeniu liczby procesorów zwiększamy rozmiary rozwiązywanych zadań
  \end{enumerate}
\end{frame}

\begin{frame}{Funkcja stałej sprawności}
  \begin{enumerate}
  \item Dla danej liczby procesorów wynikiem jest rozmiar zadania przy którym zachowywana jest sprawność
  \item Ang. isoefficiency function
  \item Jest to funkcja rosnąca
  \item Mówimy, że architektura jest bardziej skalowalna, gdy ta funkcja rośnie wolniej
  \end{enumerate}
\end{frame}

\section{Rozdział 3. Architektury maszyn równoległych}

\begin{frame}{Architektury maszyn równoległych}
  \huge
  \begin{center}
    Rodział 3

    Architektury maszyn równoległych
  \end{center}
\end{frame}

\begin{frame}{Procesory wielordzeniowe}
  \begin{enumerate}
  \item wiele jednostek obliczeniowych dzielących magistralę
  \item czasami też L2 cache
  \end{enumerate}
\end{frame}

\begin{frame}{Hyper Threading}
  \begin{enumerate}
  \item wolne cykle (czekanie na IO)
  \item dwa wątki na procesorze jednordzeniowym z powodu dużej liczby wolnych cykli
  \item wątki są przełączane
  \end{enumerate}
\end{frame}

\begin{frame}{Rozszerzenia strumieniowe}
  \begin{enumerate}
  \item realizacja podstawowych operacji arytmetycznych na wektorze w sposób równoległy
  \item dodatkowe jendostki przeznaczone tylko do tej pracy
  \end{enumerate}
\end{frame}

\begin{frame}{Obliczenia na kartach graficznych}
  \begin{enumerate}
  \item kary graficzne maja wiele jednostek przetwarzajacych dane (nawet kilkaset)
  \item jest to konsekwencją [w dużej mierze] równoległej natury procesu wyświetlania grafiki
  \item kiedyś potok graficzny był nieprogramowalny - algorytmy do przetwarzania wierzchołków/pikseli były zapisane w sprzęcie
  \end{enumerate}
\end{frame}

\begin{frame}{Obliczenia na kartach graficznych 2}
  \begin{enumerate}
  \item jednostki przetwarzania ogólnego zastosowania
  \item pojawienie się shaderów
  \item koniec stałego potoku graficznego
  \item GPGPU - General Purpose Computing on Graphics Procesing Units
  \item Tesla - nVidia, FireStream - AMD
  \end{enumerate}
\end{frame}

\begin{frame}{Hybrydyzacja obliczeń}
  \begin{enumerate}
  \item czyli korzystanie z różnorodnych jednostek wykonawczych
  \item różne reprezentacje typów danych (endianness: PowerPC - big, x86 - little)
  \item różne precyzje typów danych (halves/partials na GPU to liczby zmiennoprzecinkowe 16-bitowe, są też 32-bitowe)
  \item IBM Roadrunner - kilkanaście tysięcy procesorów AMD (2 rdzenie, x86) i tyle samo procesorów z Playstation 3 (1 rdzeń PowerPC, 8 rdzeni do obliczeń wektorowych)
  \end{enumerate}
\end{frame}

\begin{frame}{Krótko o superkomputerach}
  \begin{enumerate}
  \item Najczęściej są to połączone procesory spotykane w komputerach osobistych
  \item Klastry wieloprocesorów (wspólna pamięć) połączone szybkimi sieciami wewnętrznymi
  \item Coraz rzadziej wykorzystuje się procesory dedykowane do obliczeń wektorowych
  \end{enumerate}
\end{frame}

\section{Klasyfikacja maszyn równoległych}

\begin{frame}{Klasyfikacja maszyn równoległych wg Flynna}
  \begin{enumerate}
  \item SISD - klasyczna maszyna sekwencyjna
  \item SIMD - procesory wektorowe, procesory z jednostkami wktorowymi
  \item MISD - tylko specyficzne zastosowania
  \item MIMD - równoległa praca na wielu różnych danych
  \end{enumerate}
\end{frame}

\begin{frame}{Klasyfikacja maszyn równoległych ze względu na rodzaj pamięci}
  \begin{enumerate}
  \item Pamięć dzielona - wspólna przestrzeń adresowa
  \item Pamięć lokalna - należy samemu podzielić dane
  \end{enumerate}
\end{frame}

\begin{frame}{Równoległość w maszynach typu SISD}
  \begin{enumerate}
  \item Przetwarzanie potokowe - kilka taktów na instrukcję (pobranie rozkazu, jego argumentów, operacje arytmetyczne, zapis, ...); w momencie zwolnienia fragmentu procesora rozpoczynane jest wykonywanie następnej instrukcji
  \item Rozszerzenia strumieniowe - nowe rozkazy procesora wykonujące obliczenia równoległe na danych mniejszej precyzji (przykłady: MMX, SSE$\{\epsilon,2,3\}$, AltiVec, 3DNow!)
  \item Hyper Threading - dwa wątki na procesor przełączane przy oczekiwaniu na IO
  \end{enumerate}
\end{frame}

\begin{frame}{Równoległość w maszynach typu SIMD}
  \begin{enumerate}
  \item SM-SIMD
  \item DM-SIMD
  \end{enumerate}
\end{frame}

\begin{frame}{Równoległość w maszynach typu SM-SIMD}
  \begin{enumerate}
  \item Inaczej komputer wektorowy - składa się z jednego procesora wektorowego
  \item Dane zawsze są w paczkach o stałej liczności zależnej od procesora wektorowego
  \item Wykonywanie ciągów tych samych operacji
  \item Zaleta: łatwe programowanie takich maszyn
  \end{enumerate}
\end{frame}

\begin{frame}{Równoległość w maszynach typu DM-SIMD}
  \begin{enumerate}
  \item Siatka 2D lub 3D prostych procesorów + procesor nadzorujący
  \item Każdy prosty procesor ma swoje dane lokalne i na nich wykonuje obliczenia zlecone przez procesor nadzorujący
  \item Szybka wymiana informacji między sąsiednimi prostymi procesorami
  \item Powolny routing między dalszymi procesorami
  \item Ten model realizują karty graficzne
  \item Programista odpowiada za podział pamięci
  \end{enumerate}
\end{frame}

\begin{frame}{Równoległość w maszynach typu MIMD}
  \begin{enumerate}
  \item SM-MIMD
  \item DM-MIMD
  \end{enumerate}
\end{frame}

\begin{frame}{Równoległość w maszynach typu SM-MIMD}
  \begin{enumerate}
  \item Niewielka liczba procesorów z lokalną pamięcią
  \item Dostęp do globalnej pamięci
  \item Magistrala (tania - liniowo połączeń do niej, wolniejsza) lub przełączniki krzyżowe (drogie - $p^2$ przełączników, szybsze)
  \item Cache'ing z powodu drogiego dostępu do globalnej pamięci; utrzymywanie spójności
  \item Łatwość programowania z powodu istnienia wspólnej przestrzeni adresowej
  \end{enumerate}
\end{frame}

\begin{frame}{Równoległość w maszynach typu DM-MIMD}
  \begin{enumerate}
  \item Najpopularniejsza i najdynamiczniej rozwijana
  \item Lokalna pamięć każdego procesora
  \item Trudniejsze programowanie ze względu na konieczność przesyłania komunikatów
  \end{enumerate}
\end{frame}

\begin{frame}{Topologia maszyn typu DM-MIMD}
  \begin{enumerate}
  \item Topologia to sposów połączeń procesorów
  \item Średnica (mniejsza wartość lepsza)
  \item Podział połówkowy - najmniejsza liczba kanałów, po usunięciu których system będzie podzielony na dwie równe części (większa wartość lepsza)
  \end{enumerate}
\end{frame}

\begin{frame}{Przykładowe topologie maszyn typu DM-MIMD}
  \begin{enumerate}
  \item siatka dwuwymiarowa
  \item torus dwuwymiarowy
  \item pierścień (również torus jednowymiarowy)
  \item drzewa statyczne (wierzchołki = procesory)
  \item drzewa statyczne (liście = procesy, pozostałe to przełączniki)
  \item fat tree (o zwiększaniu przepustowości przy korzeniu)
  \item hipersześcian (można otrzymać inne topologie przez usuwanie krawędzi np. software'owo)
  \end{enumerate}
\end{frame}

\begin{frame}{Przykładowe topologie maszyn typu DM-MIMD}
  \begin{enumerate}
  \item cut-throught switching (siatka, podział pakietów)
  \item konstelacje - rozwiązanie hybyrdowe: węzły SM-MIMD połączone wolniejszą siecią (wolniejszą niż procesory wewnątrz węzła)
  \end{enumerate}
\end{frame}

\section{Klastry i gridy}

\begin{frame}{Klastry}
  \begin{enumerate}
  \item df.: zespół maszyn połączonych szybką siecią, które są jednolicie zarządzane
  \item najczęściej oparte na tej samej architekturze (homogeniczne)
  \item najczęściej pracujące pod kontrolą jednego systemu operacyjnego
  \item najczęściej znajdujące się blisko (np. regał lub pomieszcznie)
  \item najczęściej zarządzane z jednej stacji roboczej
  \end{enumerate}
\end{frame}

\begin{frame}{Klastry realizują wiele zadań jednocześnie}
  \begin{enumerate}
  \item job scheduler (priorytet zadania, kierowanie do mniej obciążonych maszyn)
  \item konieczność mierzenia obciążenia (tzw. load balancing clusters)
  \item dążenie do wrażenia, że klaster to jedna maszyna (system plików, scheduler); tzw. Single System Image
  \end{enumerate}
\end{frame}

\begin{frame}{Przykłady oprogramowania dla klastrów}
  \begin{enumerate}
  \item Portable Batch System - najstarszy
  \item Condor - możliwość przenosznia zadań w trakcie realizacji
  \item Oracle Grid Engine - opensource (wcześniej Sun Grid Engine)
  \item Windows Compute Cluster Server - tylko x86
  \item OpenSSI - firmy HP, darmowy
  \item Kerrighed - powstał w INRIA, migracje zadań
  \item Linux Virtual Server - modyfikacje jądra w celu uzyskania SSI, migracje zadań
  \end{enumerate}
\end{frame}

\begin{frame}{Gridy}
  \begin{enumerate}
  \item df.: zbiór luźno powiązanych, rozproszonych geograficznie, heterogenicznych zasobów komunikujących się z użyciem ustalonego protokołu
  \item zasoby to: superkomputery, klastry, pc z GPU, bazy danych, aparatura naukowa, urządzenia wyjścia
  \item uogólnienie klastra
  \item większe opóźnienia - nie nadają się do obliczeń równoległych tylko rozproszonych
  \item problem podszywania się pod element grida
  \end{enumerate}
\end{frame}

\begin{frame}{Zastosowania gridów i klastrów}
  \begin{enumerate}
  \item klastry nadają się do obliczeń numerycznych, optymalizacji
  \item gridy nadają się do ...
  \item seti at home, fightAISD at home
  \end{enumerate}
\end{frame}

\end{document}
